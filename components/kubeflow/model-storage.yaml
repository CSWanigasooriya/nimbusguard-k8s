---
# Persistent Volume Claim for model storage
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nimbusguard-model-pvc
  namespace: nimbusguard-serving
  labels:
    app.kubernetes.io/name: nimbusguard
    app.kubernetes.io/component: model-storage
    app.kubernetes.io/part-of: kubeflow
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  # Use default storage class
  # storageClassName: ""

---
# MinIO Secret for model storage access
apiVersion: v1
kind: Secret
metadata:
  name: minio-model-storage-secret
  namespace: nimbusguard-serving
type: Opaque
data:
  # MinIO credentials for model storage
  # endpoint: minio-api.minio.svc.cluster.local:9000 (base64 encoded)
  endpoint: bWluaW8tYXBpLm1pbmlvLnN2Yy5jbHVzdGVyLmxvY2FsOjkwMDA=
  # access-key: nimbusguard (base64 encoded)
  access-key: bmltYnVzZ3VhcmQ=
  # secret-key: nimbusguard123 (base64 encoded)  
  secret-key: bmltYnVzZ3VhcmQxMjM=
  # bucket: models (base64 encoded)
  bucket: bW9kZWxz
  # region: us-east-1 (base64 encoded)
  region: dXMtZWFzdC0x

---
# ConfigMap for MinIO model storage configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: minio-model-config
  namespace: nimbusguard-serving
data:
  endpoint: "minio-api.minio.svc.cluster.local:9000"
  bucket: "models"
  region: "us-east-1"
  use_ssl: "false"

---
# ConfigMap with model loading instructions
apiVersion: v1
kind: ConfigMap
metadata:
  name: model-loader-script
  namespace: nimbusguard-serving
data:
  load_model.py: |
    #!/usr/bin/env python3
    """
    Model loader script for NimbusGuard DQN models
    Loads models from MinIO S3-compatible storage and prepares them for inference
    """
    
    import os
    import torch
    import pickle
    import json
    import boto3
    import tempfile
    from datetime import datetime
    from pathlib import Path
    from botocore.exceptions import ClientError
    
    def get_s3_client():
        """Get S3 client for MinIO"""
        return boto3.client(
            's3',
            endpoint_url=f"http://{os.getenv('MINIO_ENDPOINT', 'minio-api.minio.svc.cluster.local:9000')}",
            aws_access_key_id=os.getenv('MINIO_ACCESS_KEY', 'nimbusguard'),
            aws_secret_access_key=os.getenv('MINIO_SECRET_KEY', 'nimbusguard123'),
            region_name=os.getenv('MINIO_REGION', 'us-east-1')
        )
    
    def save_dqn_model(model, model_name="nimbusguard-dqn", version="latest"):
        """Save a trained DQN model to MinIO storage"""
        s3_client = get_s3_client()
        bucket = os.getenv('MINIO_BUCKET', 'models')
        
        # Create temporary directory for model files
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            # Save PyTorch model
            model_file = temp_path / "model.pth"
            torch.save(model.state_dict(), model_file)
            
            # Save model metadata
            metadata = {
                "model_name": model_name,
                "version": version,
                "state_dim": getattr(model, 'state_dim', 11),
                "action_dim": getattr(model, 'action_dim', 5),
                "created_at": str(datetime.now()),
                "framework": "pytorch"
            }
            
            metadata_file = temp_path / "metadata.json"
            with open(metadata_file, "w") as f:
                json.dump(metadata, f, indent=2)
            
            # Upload to MinIO
            model_key = f"{model_name}/{version}/model.pth"
            metadata_key = f"{model_name}/{version}/metadata.json"
            
            try:
                s3_client.upload_file(str(model_file), bucket, model_key)
                s3_client.upload_file(str(metadata_file), bucket, metadata_key)
                print(f"Model saved to MinIO: s3://{bucket}/{model_name}/{version}/")
                return f"s3://{bucket}/{model_name}/{version}/"
            except ClientError as e:
                print(f"Error uploading model: {e}")
                raise
    
    def load_dqn_model(model_class, model_name="nimbusguard-dqn", version="latest"):
        """Load a DQN model from MinIO storage"""
        s3_client = get_s3_client()
        bucket = os.getenv('MINIO_BUCKET', 'models')
        
        model_key = f"{model_name}/{version}/model.pth"
        metadata_key = f"{model_name}/{version}/metadata.json"
        
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            
            try:
                # Download metadata
                metadata_file = temp_path / "metadata.json"
                s3_client.download_file(bucket, metadata_key, str(metadata_file))
                
                with open(metadata_file, "r") as f:
                    metadata = json.load(f)
                
                # Download model
                model_file = temp_path / "model.pth"
                s3_client.download_file(bucket, model_key, str(model_file))
                
                # Initialize model
                model = model_class(
                    state_dim=metadata["state_dim"],
                    action_dim=metadata["action_dim"]
                )
                
                # Load weights
                model.load_state_dict(torch.load(model_file))
                model.eval()
                
                print(f"Model loaded from MinIO: s3://{bucket}/{model_name}/{version}/")
                return model, metadata
                
            except ClientError as e:
                print(f"Error loading model: {e}")
                raise FileNotFoundError(f"Model not found: s3://{bucket}/{model_name}/{version}/")
    
    def list_available_models():
        """List all available models in MinIO storage"""
        s3_client = get_s3_client()
        bucket = os.getenv('MINIO_BUCKET', 'models')
        models = []
        
        try:
            # List objects in bucket
            response = s3_client.list_objects_v2(Bucket=bucket)
            
            if 'Contents' not in response:
                return models
            
            # Group by model name and version
            model_versions = {}
            for obj in response['Contents']:
                key = obj['Key']
                if key.endswith('/metadata.json'):
                    parts = key.split('/')
                    if len(parts) >= 3:
                        model_name = parts[0]
                        version = parts[1]
                        
                        if model_name not in model_versions:
                            model_versions[model_name] = []
                        model_versions[model_name].append(version)
            
            # Get metadata for each model version
            for model_name, versions in model_versions.items():
                for version in versions:
                    try:
                        metadata_key = f"{model_name}/{version}/metadata.json"
                        
                        with tempfile.NamedTemporaryFile(mode='w+', suffix='.json') as temp_file:
                            s3_client.download_file(bucket, metadata_key, temp_file.name)
                            
                            with open(temp_file.name, 'r') as f:
                                metadata = json.load(f)
                            
                            models.append({
                                "name": model_name,
                                "version": version,
                                "path": f"s3://{bucket}/{model_name}/{version}/",
                                "metadata": metadata
                            })
                    except ClientError:
                        continue
            
            return models
            
        except ClientError as e:
            print(f"Error listing models: {e}")
            return []
    
    if __name__ == "__main__":
        print("Available models in MinIO:")
        for model in list_available_models():
            print(f"  {model['name']}:{model['version']} - {model['path']}")
  
  setup_models.sh: |
    #!/bin/bash
    # Setup script for MinIO model storage
    
    echo "Setting up MinIO model storage..."
    
    # Install MinIO client if not present
    if ! command -v mc &> /dev/null; then
        echo "Installing MinIO client..."
        curl -fsSL https://dl.min.io/client/mc/release/linux-amd64/mc -o /usr/local/bin/mc
        chmod +x /usr/local/bin/mc
    fi
    
    # Configure MinIO client
    MINIO_ENDPOINT=${MINIO_ENDPOINT:-"minio-api.minio.svc.cluster.local:9000"}
    MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-"nimbusguard"}
    MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-"nimbusguard123"}
    MINIO_BUCKET=${MINIO_BUCKET:-"models"}
    
    echo "Configuring MinIO client..."
    mc alias set minio http://$MINIO_ENDPOINT $MINIO_ACCESS_KEY $MINIO_SECRET_KEY
    
    # Create bucket if it doesn't exist
    echo "Creating models bucket..."
    mc mb minio/$MINIO_BUCKET --ignore-existing
    
    # Create directory structure in bucket
    echo "Setting up model directory structure..."
    echo '{"info": "NimbusGuard DQN models directory"}' | mc pipe minio/$MINIO_BUCKET/nimbusguard-dqn/.info
    echo '{"info": "Model checkpoints directory"}' | mc pipe minio/$MINIO_BUCKET/checkpoints/.info
    
    echo "MinIO model storage setup complete!"
    echo "Available buckets:"
    mc ls minio/
    
    echo "Models bucket structure:"
    mc ls minio/$MINIO_BUCKET --recursive 