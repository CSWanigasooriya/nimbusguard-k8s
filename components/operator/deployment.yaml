apiVersion: apps/v1
kind: Deployment
metadata:
  name: nimbusguard-operator
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: nimbusguard-operator
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nimbusguard-operator
        component: nimbusguard-operator
      annotations:
        # This annotation is crucial. It tells Alloy/Prometheus to scrape this pod.
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: nimbusguard-operator-sa
      containers:
      - name: adapter
        # NOTE: You will need to build and push this image to your registry.
        image: nimbusguard-operator:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          name: metrics
        - containerPort: 8081
          name: health
        env:
        # OpenAI API key for LLM validation (OPTIONAL - only needed if LLM features are enabled)
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openai-api-key
              key: key
              optional: true
        # Service URLs
        - name: PROMETHEUS_URL
          value: "http://prometheus.nimbusguard.svc:9090"
        - name: MCP_SERVER_URL
          value: "http://mcp-server.nimbusguard.svc:8080"
        - name: REDIS_URL
          value: "redis://redis.nimbusguard.svc:6379"
        
        # === AI MODEL CONFIGURATION ===
        - name: AI_MODEL
          value: "gpt-4-turbo"  # 128K context window for complex LLM validation
        - name: AI_TEMPERATURE
          value: "0.1"  # Low temperature for consistent reasoning
        
        # === SIMPLIFIED AI CONFIGURATION ===
        - name: ENABLE_DETAILED_REASONING
          value: "true"  # Enable comprehensive AI reasoning logs
        - name: ENABLE_LLM_VALIDATION
          value: "false"     # DISABLED - Simplified DQN without LLM overrides
        - name: ENABLE_LLM_REWARDS
          value: "false"     # DISABLED - Using simplified metric-based rewards only
        
        # === SIMPLIFIED DQN EXPLORATION ===
        - name: EPSILON_START
          value: "0.2"    # Start with 20% exploration
        - name: EPSILON_END
          value: "0.01"   # End with 1% exploration
        - name: EPSILON_DECAY
          value: "0.995"  # Gradual decay for stable learning
        
        # === SIMPLIFIED DQN TRAINING ===
        - name: GAMMA
          value: "0.99"       # Standard discount factor
        - name: LEARNING_RATE
          value: "0.001"      # Balanced learning rate
        - name: MEMORY_CAPACITY
          value: "10000"      # Smaller replay buffer for faster learning
        - name: MIN_BATCH_SIZE
          value: "8"          # Minimum batch size for training
        - name: BATCH_SIZE
          value: "32"         # Standard batch size
        - name: TARGET_BATCH_SIZE
          value: "32"         # Target batch size
        - name: TARGET_UPDATE_INTERVAL
          value: "100"        # Frequent target network updates
        
        # === NEURAL NETWORK ARCHITECTURE ===
        - name: DQN_HIDDEN_DIMS
          value: "64,32"      # Simple 2-layer architecture
        
        # === LSTM FORECASTING CONFIGURATION ===
        - name: FORECASTING_ENABLED
          value: "true"       # Enable LSTM forecasting
        - name: FORECASTING_HORIZON_MINUTES
          value: "1"         # Forecast 10 minutes ahead
        - name: FORECASTING_LOOKBACK_MINUTES
          value: "5"         # Use 5 minutes of historical data
        - name: LSTM_HIDDEN_UNITS
          value: "64"         # LSTM hidden layer size
        - name: LSTM_NUM_LAYERS
          value: "2"          # Number of LSTM layers
        - name: LSTM_LEARNING_RATE
          value: "0.001"      # LSTM learning rate
        - name: FORECAST_RETRAIN_INTERVAL
          value: "60"         # Retrain LSTM every 60 minutes
        - name: LSTM_SEQUENCE_LENGTH
          value: "15"         # Sequence length for LSTM
        - name: LSTM_MIN_TRAINING_SAMPLES
          value: "20"         # Minimum samples for training
        - name: LSTM_VALIDATION_SPLIT
          value: "0.2"        # Validation split ratio
        - name: LSTM_EARLY_STOPPING_PATIENCE
          value: "10"         # Early stopping patience
        - name: LSTM_BATCH_SIZE
          value: "8"          # LSTM batch size
        - name: LSTM_MAX_EPOCHS
          value: "100"        # Maximum training epochs
        
        # === REWARD SYSTEM CONFIGURATION ===
        - name: REWARD_CURRENT_WEIGHT
          value: "0.7"        # Weight for current state reward (forecast gets 1 - this value)
        
        # === SCALING CONFIGURATION ===
        - name: TARGET_DEPLOYMENT
          value: "consumer"   # Target deployment to scale
        - name: TARGET_NAMESPACE
          value: "nimbusguard"
        - name: PYTHONUNBUFFERED
          value: "1"
        
        # === SIMPLIFIED STARTUP ===
        - name: FORCE_FRESH_MODEL
          value: "true"       # Start with fresh model
        - name: CLEAR_EXPERIENCE_BUFFER
          value: "true"       # Clear experience buffer
        - name: RESET_EPSILON_ON_LOAD
          value: "true"       # Reset epsilon to start values
        
        readinessProbe:
          exec:
            command:
            - timeout
            - "5"
            - curl
            - "-f"
            - "http://localhost:8080/healthz"
          initialDelaySeconds: 15
          periodSeconds: 10
          timeoutSeconds: 10
          failureThreshold: 5
        livenessProbe:
          exec:
            command:
            - timeout
            - "5"
            - curl
            - "-f"
            - "http://localhost:8080/healthz"
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m" 