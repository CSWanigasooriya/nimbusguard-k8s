---
# Loki ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: nimbusguard
  labels:
    app.kubernetes.io/name: nimbusguard
    app.kubernetes.io/component: loki
data:
  loki.yaml: |
    auth_enabled: false
    
    server:
      http_listen_port: 3100
      grpc_listen_port: 9095
      
    common:
      path_prefix: /tmp/loki
      storage:
        filesystem:
          chunks_directory: /tmp/loki/chunks
          rules_directory: /tmp/loki/rules
      replication_factor: 1
      ring:
        instance_addr: 127.0.0.1
        kvstore:
          store: inmemory
          
    query_range:
      results_cache:
        cache:
          embedded_cache:
            enabled: true
            max_size_mb: 100
            
    schema_config:
      configs:
        - from: 2020-10-24
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h
            
    ruler:
      alertmanager_url: http://localhost:9093
      
    # By default, Loki will send anonymous, but uniquely-identifiable usage and configuration
    # analytics to Grafana Labs. These statistics are sent to https://stats.grafana.org/
    #
    # Statistics help us better understand how Loki is used, and they show us performance
    # levels for most users. This helps us prioritize features and documentation.
    # For more information on what's sent: https://github.com/grafana/loki/blob/main/docs/sources/configuration/telemetry.md
    # Refer to the buildReport method to see what goes into a report.
    #
    # If you would like to disable reporting, uncomment the following lines:
    #analytics:
    #  reporting_enabled: false

---
# Loki Service
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: nimbusguard
  labels:
    app.kubernetes.io/name: nimbusguard
    app.kubernetes.io/component: loki
spec:
  type: ClusterIP
  ports:
  - port: 3100
    targetPort: 3100
    protocol: TCP
    name: http
  - port: 9095
    targetPort: 9095
    protocol: TCP
    name: grpc
  selector:
    app.kubernetes.io/name: nimbusguard
    app.kubernetes.io/component: loki

---
# Loki Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki
  namespace: nimbusguard
  labels:
    app.kubernetes.io/name: nimbusguard
    app.kubernetes.io/component: loki
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: nimbusguard
      app.kubernetes.io/component: loki
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nimbusguard
        app.kubernetes.io/component: loki
    spec:
      containers:
      - name: loki
        image: grafana/loki:2.9.0
        args:
        - -config.file=/etc/loki/loki.yaml
        - -target=all
        ports:
        - containerPort: 3100
          name: http
        - containerPort: 9095
          name: grpc
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 30
          periodSeconds: 15
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        volumeMounts:
        - name: config
          mountPath: /etc/loki
        - name: storage
          mountPath: /tmp/loki
      volumes:
      - name: config
        configMap:
          name: loki-config
      - name: storage
        emptyDir: {}

---
# Promtail ConfigMap for log collection
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: nimbusguard
  labels:
    app.kubernetes.io/name: nimbusguard
    app.kubernetes.io/component: promtail
data:
  promtail.yaml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0
      
    positions:
      filename: /tmp/positions.yaml
      
    clients:
      - url: http://loki:3100/loki/api/v1/push
      
    scrape_configs:
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
              - nimbusguard
      pipeline_stages:
        - cri: {}
      relabel_configs:
        - source_labels:
            - __meta_kubernetes_pod_controller_name
          regex: ([0-9a-z-.]+?)(-[0-9a-f]{8,10})?
          action: replace
          target_label: __tmp_controller_name
        - source_labels:
            - __meta_kubernetes_pod_label_app_kubernetes_io_name
            - __meta_kubernetes_pod_label_app
            - __tmp_controller_name
            - __meta_kubernetes_pod_name
          regex: ^;*([^;]+)(;.*)?$
          action: replace
          target_label: app
        - source_labels:
            - __meta_kubernetes_pod_label_app_kubernetes_io_component
            - __meta_kubernetes_pod_label_component
          regex: ^;*([^;]+)(;.*)?$
          action: replace
          target_label: component
        - action: replace
          source_labels:
          - __meta_kubernetes_pod_node_name
          target_label: node_name
        - action: replace
          source_labels:
          - __meta_kubernetes_namespace
          target_label: namespace
        - action: replace
          replacement: /var/log/pods/*$1/*.log
          separator: /
          source_labels:
          - __meta_kubernetes_pod_uid
          - __meta_kubernetes_pod_container_name
          target_label: __path__

---
# Promtail DaemonSet
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: nimbusguard
  labels:
    app.kubernetes.io/name: nimbusguard
    app.kubernetes.io/component: promtail
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: nimbusguard
      app.kubernetes.io/component: promtail
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nimbusguard
        app.kubernetes.io/component: promtail
    spec:
      serviceAccountName: promtail
      containers:
      - name: promtail
        image: grafana/promtail:2.9.0
        args:
        - -config.file=/etc/promtail/promtail.yaml
        ports:
        - containerPort: 9080
          name: http
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        volumeMounts:
        - name: config
          mountPath: /etc/promtail
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: promtail-config
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      tolerations:
      - effect: NoSchedule
        operator: Exists

---
# Promtail ServiceAccount
apiVersion: v1
kind: ServiceAccount
metadata:
  name: promtail
  namespace: nimbusguard
  labels:
    app.kubernetes.io/name: nimbusguard
    app.kubernetes.io/component: promtail

---
# Promtail ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: promtail
  labels:
    app.kubernetes.io/name: nimbusguard
    app.kubernetes.io/component: promtail
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]

---
# Promtail ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: promtail
  labels:
    app.kubernetes.io/name: nimbusguard
    app.kubernetes.io/component: promtail
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: promtail
subjects:
- kind: ServiceAccount
  name: promtail
  namespace: nimbusguard 