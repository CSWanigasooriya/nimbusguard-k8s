apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: consumer-scaledobject
spec:
  scaleTargetRef:
    name: consumer
  minReplicaCount: 1
  maxReplicaCount: 15
  pollingInterval: 30
  cooldownPeriod: 300
  advanced:
    # Intelligent scaling behavior
    horizontalPodAutoscalerConfig:
      behavior:
        scaleUp:
          stabilizationWindowSeconds: 60
          policies:
          - type: Percent
            value: 50  # Scale up by 50% max
            periodSeconds: 60
        scaleDown:
          stabilizationWindowSeconds: 300
          policies:
          - type: Percent
            value: 10  # Scale down slowly (10% max)
            periodSeconds: 60
  triggers:
    # Scale based on HTTP request rate (using actual available metric)
    - type: prometheus
      metadata:
        serverAddress: http://prometheus.nimbusguard.svc.cluster.local:9090
        metricName: http_requests_rate
        threshold: '5'
        query: sum(rate(http_requests_total{instance="consumer:8000"}[1m]))
    
    # Scale based on HTTP request duration (application latency indicator)
    - type: prometheus
      metadata:
        serverAddress: http://prometheus.nimbusguard.svc.cluster.local:9090
        metricName: http_request_duration_avg
        threshold: '2'
        query: sum(rate(http_request_duration_seconds_sum{instance="consumer:8000"}[1m])) / sum(rate(http_request_duration_seconds_count{instance="consumer:8000"}[1m]))
        
    # Scale based on Python garbage collection pressure
    - type: prometheus
      metadata:
        serverAddress: http://prometheus.nimbusguard.svc.cluster.local:9090
        metricName: python_gc_rate
        threshold: '0.5'
        query: sum(rate(python_gc_collections_total{instance="consumer:8000"}[1m])) 