apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: consumer-scaler
  namespace: nimbusguard
spec:
  scaleTargetRef:
    name: consumer
  minReplicaCount: 1
  maxReplicaCount: 50
  pollingInterval: 30
  cooldownPeriod: 5
  triggers:
    - type: prometheus
      metadata:
        serverAddress: http://prometheus.nimbusguard.svc:9090
        metricName: http_request_rate
        threshold: '5'
        query: |
          sum(rate(http_requests_total{handler="/process",job="prometheus.scrape.annotated_pods",method="POST"}[1m]))
    - type: prometheus
      metadata:
        serverAddress: http://prometheus.nimbusguard.svc:9090
        metricName: http_request_duration
        threshold: '2'
        query: |
          sum(rate(http_request_duration_seconds_sum{handler="/process",job="prometheus.scrape.annotated_pods",method="POST"}[1m])) / sum(rate(http_request_duration_seconds_count{handler="/process",job="prometheus.scrape.annotated_pods",method="POST"}[1m]))
    - type: prometheus
      metadata:
        serverAddress: http://prometheus.nimbusguard.svc:9090
        metricName: python_gc_pressure
        threshold: '0.5'
        query: |
          sum(rate(python_gc_collections_total{job="prometheus.scrape.annotated_pods"}[2m]))

    # Resource utilization trigger - CPU (avg over 3m)
    - type: prometheus
      metadata:
        serverAddress: http://prometheus.nimbusguard.svc.cluster.local:9090
        metricName: process_cpu_usage_percent
        threshold: '50'
        query: |
          avg(rate(process_cpu_seconds_total{instance="consumer:8000"}[3m])) * 100

    # Resource utilization trigger - Memory (95th percentile over 5m)
    - type: prometheus
      metadata:
        serverAddress: http://prometheus.nimbusguard.svc.cluster.local:9090
        metricName: process_memory_usage_mb
        threshold: '300'
        query: |
          quantile_over_time(0.95, process_resident_memory_bytes{instance="consumer:8000"}[5m]) / 1024 / 1024 