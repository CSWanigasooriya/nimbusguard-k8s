apiVersion: apps/v1
kind: Deployment
metadata:
  name: dqn-adapter
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: dqn-adapter
  template:
    metadata:
      labels:
        app.kubernetes.io/name: dqn-adapter
        component: dqn-adapter
      annotations:
        # This annotation is crucial. It tells Alloy/Prometheus to scrape this pod.
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: dqn-adapter-sa
      containers:
      - name: adapter
        # NOTE: You will need to build and push this image to your registry.
        image: nimbusguard-dqn-adapter:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
          name: metrics
        - containerPort: 9091
          name: grpc
        env:
        # OpenAI API key for LLM validation (only required when ENABLE_LLM_VALIDATION=true)
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openai-api-key
              key: key
              optional: true  # Optional - only needed when LLM validation is enabled
        # Service URLs
        - name: PROMETHEUS_URL
          value: "http://prometheus.nimbusguard.svc:9090"
        - name: MCP_SERVER_URL
          value: "http://mcp-server.nimbusguard.svc:8080"
        - name: REDIS_URL
          value: "redis://redis.nimbusguard.svc:6379"
        
        # === AI MODEL CONFIGURATION ===
        - name: AI_MODEL
          value: "gpt-4-turbo"  # 128K context window for complex LLM validation
        - name: AI_TEMPERATURE
          value: "0.1"  # Low temperature for consistent reasoning
        
        # === EXPLAINABLE AI CONFIGURATION ===
        - name: ENABLE_DETAILED_REASONING
          value: "true"  # Enable comprehensive AI reasoning logs
        # REMOVED: REASONING_LOG_LEVEL - defined in config but not used in code
        - name: ENABLE_LLM_VALIDATION
          value: "true"  # Enabled for enhanced AI reasoning validation
        
        # === DQN EXPLORATION STRATEGY ===
        - name: EPSILON_START
          value: "0.3"    # Initial exploration probability
        - name: EPSILON_END
          value: "0.05"   # Final exploration probability
        - name: EPSILON_DECAY
          value: "0.99"  # Faster decay for 6-hour research evaluation
        
        # === DQN TRAINING HYPERPARAMETERS ===
        - name: GAMMA
          value: "0.99"     # Discount factor for future rewards
        - name: LEARNING_RATE
          value: "0.0003"   # Increased learning rate for faster adaptation
        - name: MEMORY_CAPACITY
          value: "50000"    # Replay buffer size
        - name: MIN_BATCH_SIZE
          value: "4"        # Reduced minimum for faster training start
        - name: BATCH_SIZE
          value: "16"       # Reduced for more frequent training
        - name: TARGET_BATCH_SIZE
          value: "32"       # Reduced target batch size
        - name: TARGET_UPDATE_INTERVAL
          value: "1000"     # Steps between target network updates
        
        # === NEURAL NETWORK ARCHITECTURE ===
        - name: DQN_HIDDEN_DIMS
          value: "64,32"        # Optimized for 9 input features (was 512,256,128 - overkill)
        
        
        # === REWARD SYSTEM CONFIGURATION ===
        - name: STABILIZATION_PERIOD_SECONDS
          value: "15"            # Decision interval (matches HPA/KEDA evaluation)
        # REMOVED: REWARD_LATENCY_WEIGHT - not used in calculate_stable_reward function
        # REMOVED: REWARD_REPLICA_COST - not used in calculate_stable_reward function  
                 # Use improved multi-objective reward system
        
        # === MULTI-OBJECTIVE REWARD WEIGHTS ===
        - name: REWARD_PERFORMANCE_WEIGHT
          value: "0.40"         # Performance component weight (40%)
        - name: REWARD_RESOURCE_WEIGHT
          value: "0.30"         # Resource efficiency weight (30%)
        - name: REWARD_HEALTH_WEIGHT
          value: "0.20"         # System health weight (20%)
        - name: REWARD_COST_WEIGHT
          value: "0.10"         # Cost optimization weight (10%)
        
        # === EVALUATION & MONITORING ===
        - name: EVALUATION_INTERVAL
          value: "300"          # Evaluation frequency in seconds (5 minutes)
        - name: ENABLE_EVALUATION_OUTPUTS
          value: "true"         # Generate evaluation reports and visualizations
        - name: SAVE_INTERVAL_SECONDS
          value: "300"          # Model save frequency in seconds (5 minutes)
        
        # === DEPLOYMENT CONFIGURATION ===
        - name: TARGET_DEPLOYMENT
          value: "consumer"  # DQN will use ACTUAL resource limits from this deployment's spec
        - name: TARGET_NAMESPACE
          value: "nimbusguard"
        - name: PYTHONUNBUFFERED
          value: "1"
        readinessProbe:
          exec:
            command:
            - timeout
            - "5"
            - curl
            - "-f"
            - "http://localhost:8080/healthz"
          initialDelaySeconds: 15
          periodSeconds: 10
          timeoutSeconds: 10
          failureThreshold: 5
        livenessProbe:
          exec:
            command:
            - timeout
            - "5"
            - curl
            - "-f"
            - "http://localhost:8080/healthz"
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m" 